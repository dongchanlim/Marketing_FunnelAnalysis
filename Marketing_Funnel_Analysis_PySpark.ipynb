{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9971676a",
   "metadata": {},
   "source": [
    "# ðŸ“Š Marketing Funnel Analysis with PySpark & Spark SQL\n",
    "Using Databricks Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MarketingFunnelAnalysis\").getOrCreate()\n",
    "\n",
    "visit_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"visit_time\", TimestampType()),\n",
    "    StructField(\"utm_source\", StringType())\n",
    "])\n",
    "\n",
    "signup_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"signup_time\", TimestampType())\n",
    "])\n",
    "\n",
    "purchase_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"purchase_time\", TimestampType()),\n",
    "    StructField(\"amount\", DoubleType())\n",
    "])\n",
    "\n",
    "visits_df = spark.read.csv(\"/path/web_visits.csv\", header=True, schema=visit_schema)\n",
    "signups_df = spark.read.csv(\"/path/user_signups.csv\", header=True, schema=signup_schema)\n",
    "purchases_df = spark.read.csv(\"/path/purchases.csv\", header=True, schema=purchase_schema)\n",
    "\n",
    "visits_df.createOrReplaceTempView(\"web_visits\")\n",
    "signups_df.createOrReplaceTempView(\"user_signups\")\n",
    "purchases_df.createOrReplaceTempView(\"purchases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW funnel_users AS\n",
    "SELECT\n",
    "  v.user_id,\n",
    "  v.utm_source,\n",
    "  v.visit_time,\n",
    "  s.signup_time,\n",
    "  p.purchase_time,\n",
    "  p.amount\n",
    "FROM web_visits v\n",
    "LEFT JOIN user_signups s ON v.user_id = s.user_id\n",
    "LEFT JOIN purchases p ON v.user_id = p.user_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funnel_summary():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT\n",
    "          COUNT(DISTINCT user_id) AS visits,\n",
    "          COUNT(DISTINCT signup_time) AS signups,\n",
    "          COUNT(DISTINCT purchase_time) AS purchases,\n",
    "          ROUND(COUNT(DISTINCT signup_time)/COUNT(DISTINCT user_id)*100, 2) AS visit_to_signup_rate,\n",
    "          ROUND(COUNT(DISTINCT purchase_time)/COUNT(DISTINCT signup_time)*100, 2) AS signup_to_purchase_rate\n",
    "        FROM funnel_users\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_by_channel():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT\n",
    "          utm_source,\n",
    "          COUNT(DISTINCT user_id) AS visitors,\n",
    "          COUNT(DISTINCT signup_time) AS signups,\n",
    "          COUNT(DISTINCT purchase_time) AS purchases,\n",
    "          ROUND(COUNT(DISTINCT signup_time)/COUNT(DISTINCT user_id)*100, 2) AS signup_rate,\n",
    "          ROUND(COUNT(DISTINCT purchase_time)/COUNT(DISTINCT signup_time)*100, 2) AS purchase_rate\n",
    "        FROM funnel_users\n",
    "        GROUP BY utm_source\n",
    "        ORDER BY visitors DESC\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import datediff\n",
    "\n",
    "def time_to_conversion():\n",
    "    return spark.sql(\"SELECT * FROM funnel_users\").withColumn(\n",
    "        \"days_to_purchase\",\n",
    "        datediff(\"purchase_time\", \"signup_time\")\n",
    "    ).select(\"user_id\", \"utm_source\", \"signup_time\", \"purchase_time\", \"days_to_purchase\").filter(\"days_to_purchase IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c748d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aov_by_channel():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT\n",
    "          utm_source,\n",
    "          COUNT(*) AS purchase_count,\n",
    "          ROUND(AVG(amount), 2) AS avg_order_value\n",
    "        FROM funnel_users\n",
    "        WHERE purchase_time IS NOT NULL\n",
    "        GROUP BY utm_source\n",
    "        ORDER BY avg_order_value DESC\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "funnel_summary().show()\n",
    "conversion_by_channel().show()\n",
    "time_to_conversion().show()\n",
    "aov_by_channel().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
